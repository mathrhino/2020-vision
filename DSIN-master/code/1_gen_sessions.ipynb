{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding: utf-8\n",
        "import gc\n",
        "\n",
        "import pandas as pd\n",
        "from joblib import Parallel, delayed\n",
        "\n",
        "from config import FRAC\n",
        "\n",
        "\n",
        "def gen_session_list_dsin(uid, t):\n",
        "    t.sort_values('time_stamp', inplace=True, ascending=True)\n",
        "    last_time = 1483574401  # pd.to_datetime(\"2017-01-05 00:00:01\")\n",
        "    session_list = []\n",
        "    session = []\n",
        "    for row in t.iterrows():\n",
        "        time_stamp = row[1]['time_stamp']\n",
        "        # pd_time = pd.to_datetime(timestamp_datetime(time_stamp))\n",
        "        delta = time_stamp - last_time\n",
        "        cate_id = row[1]['cate']\n",
        "        brand = row[1]['brand']\n",
        "        # delta.total_seconds()\n",
        "        if delta > 30 * 60:  # Session begin when current behavior and the last behavior are separated by more than 30 minutes.\n",
        "            if len(session) > 2:  # Only use sessions that have >2 behaviors\n",
        "                session_list.append(session[:])\n",
        "            session = []\n",
        "\n",
        "        session.append((cate_id, brand, time_stamp))\n",
        "        last_time = time_stamp\n",
        "    if len(session) > 2:\n",
        "        session_list.append(session[:])\n",
        "    return uid, session_list\n",
        "\n",
        "\n",
        "def gen_session_list_din(uid, t):\n",
        "    t.sort_values('time_stamp', inplace=True, ascending=True)\n",
        "    session_list = []\n",
        "    session = []\n",
        "    for row in t.iterrows():\n",
        "        time_stamp = row[1]['time_stamp']\n",
        "        # pd_time = pd.to_datetime(timestamp_datetime())\n",
        "        # delta = pd_time  - last_time\n",
        "        cate_id = row[1]['cate']\n",
        "        brand = row[1]['brand']\n",
        "        session.append((cate_id, brand, time_stamp))\n",
        "\n",
        "    if len(session) > 2:\n",
        "        session_list.append(session[:])\n",
        "    return uid, session_list\n",
        "\n",
        "\n",
        "def applyParallel(df_grouped, func, n_jobs, backend='multiprocessing'):\n",
        "    \"\"\"Use Parallel and delayed \"\"\"  # backend='threading'\n",
        "    results = Parallel(n_jobs=n_jobs, verbose=4, backend=backend)(\n",
        "        delayed(func)(name, group) for name, group in df_grouped)\n",
        "\n",
        "    return {k: v for k, v in results}\n",
        "\n",
        "\n",
        "def gen_user_hist_sessions(model, FRAC=0.25):\n",
        "    if model not in ['din', 'dsin']:\n",
        "        raise ValueError('model must be din or dmsn')\n",
        "\n",
        "    print(\"gen \" + model + \" hist sess\", FRAC)\n",
        "    name = '../sampled_data/behavior_log_pv_user_filter_enc_' + str(FRAC) + '.pkl'\n",
        "    data = pd.read_pickle(name)\n",
        "    data = data.loc[data.time_stamp >= 1493769600]  # 0503-0513\n",
        "    # 0504~1493856000\n",
        "    # 0503 1493769600\n",
        "\n",
        "    user = pd.read_pickle('../sampled_data/user_profile_' + str(FRAC) + '.pkl')\n",
        "\n",
        "    n_samples = user.shape[0]\n",
        "    print(n_samples)\n",
        "    batch_size = 150000\n",
        "    iters = (n_samples - 1) // batch_size + 1\n",
        "\n",
        "    print(\"total\", iters, \"iters\", \"batch_size\", batch_size)\n",
        "    for i in range(0, iters):\n",
        "        target_user = user['userid'].values[i * batch_size:(i + 1) * batch_size]\n",
        "        sub_data = data.loc[data.user.isin(target_user)]\n",
        "        print(i, 'iter start')\n",
        "        df_grouped = sub_data.groupby('user')\n",
        "        if model == 'din':\n",
        "            user_hist_session = applyParallel(\n",
        "                df_grouped, gen_session_list_din, n_jobs=20, backend='loky')\n",
        "        else:\n",
        "            user_hist_session = applyParallel(\n",
        "                df_grouped, gen_session_list_dsin, n_jobs=20, backend='multiprocessing')\n",
        "        pd.to_pickle(user_hist_session, '../sampled_data/user_hist_session_' +\n",
        "                     str(FRAC) + '_' + model + '_' + str(i) + '.pkl')\n",
        "        print(i, 'pickled')\n",
        "        del user_hist_session\n",
        "        gc.collect()\n",
        "        print(i, 'del')\n",
        "\n",
        "    print(\"1_gen \" + model + \" hist sess done\")\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    gen_user_hist_sessions('din', FRAC)\n",
        "    gen_user_hist_sessions('dsin', FRAC)\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}