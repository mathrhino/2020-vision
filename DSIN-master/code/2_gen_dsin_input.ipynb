{
  "cells": [
    {
      "cell_type": "code",
      "metadata": {},
      "source": [
        "# coding: utf-8\n",
        "\n",
        "import os\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from deepctr.utils import SingleFeat\n",
        "from sklearn.preprocessing import LabelEncoder, StandardScaler\n",
        "from tensorflow.python.keras.preprocessing.sequence import pad_sequences\n",
        "from tqdm import tqdm\n",
        "\n",
        "from config import DSIN_SESS_COUNT, DSIN_SESS_MAX_LEN, FRAC\n",
        "\n",
        "FRAC = FRAC\n",
        "SESS_COUNT = DSIN_SESS_COUNT\n",
        "\n",
        "\n",
        "def gen_sess_feature_dsin(row):\n",
        "    sess_count = DSIN_SESS_COUNT\n",
        "    sess_max_len = DSIN_SESS_MAX_LEN\n",
        "    sess_input_dict = {}\n",
        "    sess_input_length_dict = {}\n",
        "    for i in range(sess_count):\n",
        "        sess_input_dict['sess_' + str(i)] = {'cate_id': [], 'brand': []}\n",
        "        sess_input_length_dict['sess_' + str(i)] = 0\n",
        "    sess_length = 0\n",
        "    user, time_stamp = row[1]['user'], row[1]['time_stamp']\n",
        "    # sample_time = pd.to_datetime(timestamp_datetime(time_stamp ))\n",
        "    if user not in user_hist_session:\n",
        "        for i in range(sess_count):\n",
        "            sess_input_dict['sess_' + str(i)]['cate_id'] = [0]\n",
        "            sess_input_dict['sess_' + str(i)]['brand'] = [0]\n",
        "            sess_input_length_dict['sess_' + str(i)] = 0\n",
        "        sess_length = 0\n",
        "    else:\n",
        "        valid_sess_count = 0\n",
        "        last_sess_idx = len(user_hist_session[user]) - 1\n",
        "        for i in reversed(range(len(user_hist_session[user]))):\n",
        "            cur_sess = user_hist_session[user][i]\n",
        "            if cur_sess[0][2] < time_stamp:\n",
        "                in_sess_count = 1\n",
        "                for j in range(1, len(cur_sess)):\n",
        "                    if cur_sess[j][2] < time_stamp:\n",
        "                        in_sess_count += 1\n",
        "                if in_sess_count > 2:\n",
        "                    sess_input_dict['sess_0']['cate_id'] = [e[0] for e in cur_sess[max(0,\n",
        "                                                                                       in_sess_count - sess_max_len):in_sess_count]]\n",
        "                    sess_input_dict['sess_0']['brand'] = [e[1] for e in\n",
        "                                                          cur_sess[max(0, in_sess_count - sess_max_len):in_sess_count]]\n",
        "                    sess_input_length_dict['sess_0'] = min(\n",
        "                        sess_max_len, in_sess_count)\n",
        "                    last_sess_idx = i\n",
        "                    valid_sess_count += 1\n",
        "                    break\n",
        "        for i in range(1, sess_count):\n",
        "            if last_sess_idx - i >= 0:\n",
        "                cur_sess = user_hist_session[user][last_sess_idx - i]\n",
        "                sess_input_dict['sess_' + str(i)]['cate_id'] = [e[0]\n",
        "                                                                for e in cur_sess[-sess_max_len:]]\n",
        "                sess_input_dict['sess_' + str(i)]['brand'] = [e[1]\n",
        "                                                              for e in cur_sess[-sess_max_len:]]\n",
        "                sess_input_length_dict['sess_' +\n",
        "                                       str(i)] = min(sess_max_len, len(cur_sess))\n",
        "                valid_sess_count += 1\n",
        "            else:\n",
        "                sess_input_dict['sess_' + str(i)]['cate_id'] = [0]\n",
        "                sess_input_dict['sess_' + str(i)]['brand'] = [0]\n",
        "                sess_input_length_dict['sess_' + str(i)] = 0\n",
        "\n",
        "        sess_length = valid_sess_count\n",
        "    return sess_input_dict, sess_input_length_dict, sess_length\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\n",
        "    user_hist_session = {}\n",
        "    FILE_NUM = len(\n",
        "        list(filter(lambda x: x.startswith('user_hist_session_' + str(FRAC) + '_dsin_'),\n",
        "                    os.listdir('../sampled_data/'))))\n",
        "\n",
        "    print('total', FILE_NUM, 'files')\n",
        "\n",
        "    for i in range(FILE_NUM):\n",
        "        user_hist_session_ = pd.read_pickle(\n",
        "            '../sampled_data/user_hist_session_' + str(FRAC) + '_dsin_' + str(i) + '.pkl')  # 19,34\n",
        "        user_hist_session.update(user_hist_session_)\n",
        "        del user_hist_session_\n",
        "\n",
        "    sample_sub = pd.read_pickle(\n",
        "        '../sampled_data/raw_sample_' + str(FRAC) + '.pkl')\n",
        "\n",
        "    index_list = []\n",
        "    sess_input_dict = {}\n",
        "    sess_input_length_dict = {}\n",
        "    for i in range(SESS_COUNT):\n",
        "        sess_input_dict['sess_' + str(i)] = {'cate_id': [], 'brand': []}\n",
        "        sess_input_length_dict['sess_' + str(i)] = []\n",
        "\n",
        "    sess_length_list = []\n",
        "    for row in tqdm(sample_sub[['user', 'time_stamp']].iterrows()):\n",
        "        sess_input_dict_, sess_input_length_dict_, sess_length = gen_sess_feature_dsin(\n",
        "            row)\n",
        "        # index_list.append(index)\n",
        "        for i in range(SESS_COUNT):\n",
        "            sess_name = 'sess_' + str(i)\n",
        "            sess_input_dict[sess_name]['cate_id'].append(\n",
        "                sess_input_dict_[sess_name]['cate_id'])\n",
        "            sess_input_dict[sess_name]['brand'].append(\n",
        "                sess_input_dict_[sess_name]['brand'])\n",
        "            sess_input_length_dict[sess_name].append(\n",
        "                sess_input_length_dict_[sess_name])\n",
        "        sess_length_list.append(sess_length)\n",
        "\n",
        "    print('done')\n",
        "\n",
        "    user = pd.read_pickle('../sampled_data/user_profile_' + str(FRAC) + '.pkl')\n",
        "    ad = pd.read_pickle('../sampled_data/ad_feature_enc_' + str(FRAC) + '.pkl')\n",
        "    user = user.fillna(-1)\n",
        "    user.rename(\n",
        "        columns={'new_user_class_level ': 'new_user_class_level'}, inplace=True)\n",
        "\n",
        "    sample_sub = pd.read_pickle(\n",
        "        '../sampled_data/raw_sample_' + str(FRAC) + '.pkl')\n",
        "    sample_sub.rename(columns={'user': 'userid'}, inplace=True)\n",
        "\n",
        "    data = pd.merge(sample_sub, user, how='left', on='userid', )\n",
        "    data = pd.merge(data, ad, how='left', on='adgroup_id')\n",
        "\n",
        "    sparse_features = ['userid', 'adgroup_id', 'pid', 'cms_segid', 'cms_group_id', 'final_gender_code', 'age_level',\n",
        "                       'pvalue_level', 'shopping_level', 'occupation', 'new_user_class_level', 'campaign_id',\n",
        "                       'customer']\n",
        "\n",
        "    dense_features = ['price']\n",
        "\n",
        "    for feat in tqdm(sparse_features):\n",
        "        lbe = LabelEncoder()  # or Hash\n",
        "        data[feat] = lbe.fit_transform(data[feat])\n",
        "    mms = StandardScaler()\n",
        "    data[dense_features] = mms.fit_transform(data[dense_features])\n",
        "\n",
        "    sparse_feature_list = [SingleFeat(feat, data[feat].nunique(\n",
        "    ) + 1) for feat in sparse_features + ['cate_id', 'brand']]\n",
        "    dense_feature_list = [SingleFeat(feat, 1) for feat in dense_features]\n",
        "    sess_feature = ['cate_id', 'brand']\n",
        "\n",
        "    sess_input = []\n",
        "    sess_input_length = []\n",
        "    for i in tqdm(range(SESS_COUNT)):\n",
        "        sess_name = 'sess_' + str(i)\n",
        "        for feat in sess_feature:\n",
        "            sess_input.append(pad_sequences(\n",
        "                sess_input_dict[sess_name][feat], maxlen=DSIN_SESS_MAX_LEN, padding='post'))\n",
        "        sess_input_length.append(sess_input_length_dict[sess_name])\n",
        "\n",
        "    model_input = [data[feat.name].values for feat in sparse_feature_list] + \\\n",
        "                  [data[feat.name].values for feat in dense_feature_list]\n",
        "    sess_lists = sess_input + [np.array(sess_length_list)]\n",
        "    model_input += sess_lists\n",
        "\n",
        "    if not os.path.exists('../model_input/'):\n",
        "        os.mkdir('../model_input/')\n",
        "\n",
        "    pd.to_pickle(model_input, '../model_input/dsin_input_' +\n",
        "                 str(FRAC) + '_' + str(SESS_COUNT) + '.pkl')\n",
        "    pd.to_pickle(data['clk'].values, '../model_input/dsin_label_' +\n",
        "                 str(FRAC) + '_' + str(SESS_COUNT) + '.pkl')\n",
        "    pd.to_pickle({'sparse': sparse_feature_list, 'dense': dense_feature_list},\n",
        "                 '../model_input/dsin_fd_' + str(FRAC) + '_' + str(SESS_COUNT) + '.pkl')\n",
        "    print(\"gen dsin input done\")\n"
      ],
      "outputs": [],
      "execution_count": null
    }
  ],
  "metadata": {
    "anaconda-cloud": {},
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 1
}